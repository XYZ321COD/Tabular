{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f58e032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd2eb9",
   "metadata": {},
   "source": [
    "# Load data for the training from CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13dc9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./train.csv/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53195099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Class_1</th>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>...</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_2</th>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>...</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "      <td>16122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_3</th>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>...</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "      <td>8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_4</th>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_5</th>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>...</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "      <td>2739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_6</th>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>...</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "      <td>14135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_7</th>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>...</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "      <td>2839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_8</th>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>...</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "      <td>8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_9</th>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>...</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "      <td>4955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "target                                                                   \n",
       "Class_1   1929    1929    1929    1929    1929    1929    1929    1929   \n",
       "Class_2  16122   16122   16122   16122   16122   16122   16122   16122   \n",
       "Class_3   8004    8004    8004    8004    8004    8004    8004    8004   \n",
       "Class_4   2691    2691    2691    2691    2691    2691    2691    2691   \n",
       "Class_5   2739    2739    2739    2739    2739    2739    2739    2739   \n",
       "Class_6  14135   14135   14135   14135   14135   14135   14135   14135   \n",
       "Class_7   2839    2839    2839    2839    2839    2839    2839    2839   \n",
       "Class_8   8464    8464    8464    8464    8464    8464    8464    8464   \n",
       "Class_9   4955    4955    4955    4955    4955    4955    4955    4955   \n",
       "\n",
       "         feat_8  feat_9  ...  feat_84  feat_85  feat_86  feat_87  feat_88  \\\n",
       "target                   ...                                                \n",
       "Class_1    1929    1929  ...     1929     1929     1929     1929     1929   \n",
       "Class_2   16122   16122  ...    16122    16122    16122    16122    16122   \n",
       "Class_3    8004    8004  ...     8004     8004     8004     8004     8004   \n",
       "Class_4    2691    2691  ...     2691     2691     2691     2691     2691   \n",
       "Class_5    2739    2739  ...     2739     2739     2739     2739     2739   \n",
       "Class_6   14135   14135  ...    14135    14135    14135    14135    14135   \n",
       "Class_7    2839    2839  ...     2839     2839     2839     2839     2839   \n",
       "Class_8    8464    8464  ...     8464     8464     8464     8464     8464   \n",
       "Class_9    4955    4955  ...     4955     4955     4955     4955     4955   \n",
       "\n",
       "         feat_89  feat_90  feat_91  feat_92  feat_93  \n",
       "target                                                \n",
       "Class_1     1929     1929     1929     1929     1929  \n",
       "Class_2    16122    16122    16122    16122    16122  \n",
       "Class_3     8004     8004     8004     8004     8004  \n",
       "Class_4     2691     2691     2691     2691     2691  \n",
       "Class_5     2739     2739     2739     2739     2739  \n",
       "Class_6    14135    14135    14135    14135    14135  \n",
       "Class_7     2839     2839     2839     2839     2839  \n",
       "Class_8     8464     8464     8464     8464     8464  \n",
       "Class_9     4955     4955     4955     4955     4955  \n",
       "\n",
       "[9 rows x 94 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(path) \n",
    "data_grouped_by_target = data.groupby(['target']).count()\n",
    "display(data_grouped_by_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1434882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1840e-04, 6.2027e-05, 1.2494e-04, 3.7161e-04, 3.6510e-04, 7.0746e-05,\n",
      "        3.5224e-04, 1.1815e-04, 2.0182e-04])\n"
     ]
    }
   ],
   "source": [
    "number_of_examples_per_target = data_grouped_by_target['id']\n",
    "weights = torch.tensor(number_of_examples_per_target.values, dtype=torch.float)\n",
    "weights = 1/weights\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffcbf6",
   "metadata": {},
   "source": [
    "# Mapping target to int value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557c8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"Class_1\": 0,\n",
    "    \"Class_2\": 1,\n",
    "    \"Class_3\": 2,\n",
    "    \"Class_4\": 3,\n",
    "    \"Class_5\": 4,\n",
    "    \"Class_6\": 5,\n",
    "    \"Class_7\": 6,\n",
    "    \"Class_8\": 7,\n",
    "    \"Class_9\": 8,\n",
    "}\n",
    "def mapping_function(tensor):\n",
    "    return class_mapping[tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893492c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0de5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "class  MyDataSet(data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.root = root\n",
    "        self.train = train  # training set or test set\n",
    "        self.data, self.targets = self._load_data()\n",
    "    \n",
    "    def _load_data(self):\n",
    "            \n",
    "        data_path = f\"{'train' if self.train else 'test'}.csv\"\n",
    "        data_path = os.path.join(self.root, data_path)\n",
    "        data_csv = pd.read_csv(data_path)\n",
    "        \n",
    "        data = data_csv.drop(['id','target'], axis=1)\n",
    "        \n",
    "        targets = data_csv['target']\n",
    "        \n",
    "        return data, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (data, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        data, target = self.data.iloc[index], self.targets.iloc[index]\n",
    "        data = torch.tensor(data, dtype=torch.float)\n",
    "        target = torch.tensor(mapping_function(target), dtype=torch.long)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17d3a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    filename = './train.csv'\n",
    "    dataset = MyDataSet(filename)\n",
    "    train_data_set_lenght = int(0.8*len(dataset))\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [train_data_set_lenght, len(dataset) - train_data_set_lenght])\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=True)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e3548",
   "metadata": {},
   "source": [
    "# Optuna model search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a640d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 9\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "babd9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 2)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 93\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "#         p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "#         layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073bc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = 'Adam'\n",
    "    lr = 0.001\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    train_loader, valid_loader = get_dataset()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "        \n",
    "        if accuracy > 0.90:\n",
    "                torch.save(model.state_dict(), './model.pth')\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de866d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-18 13:27:37,146]\u001b[0m A new study created in memory with name: no-name-191b11d9-0c3f-49a4-979e-0e67f3a95692\u001b[0m\n",
      "C:\\Users\\Luxoft\\anaconda3\\envs\\upscalers_pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 7050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n",
      "\u001b[32m[I 2021-07-18 13:28:14,782]\u001b[0m Trial 0 finished with value: 0.7031351001939238 and parameters: {'n_layers': 1, 'n_units_l0': 59}. Best is trial 0 with value: 0.7031351001939238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.7031351001939238\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 59\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=1, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e9dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "# criterion = nn.CrossEntropyLoss(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e457c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8ccb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "# with torch.no_grad():\n",
    "#     for data in train_loader:\n",
    "#         images, labels = data\n",
    "#         # calculate outputs by running images through the network\n",
    "#         outputs = net(images)\n",
    "#         # the class with the highest energy is what we choose as prediction\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69a277db",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-a5d5b61aa8a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-a5d5b61aa8a6>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    .\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (upscalers_pytorch)",
   "language": "python",
   "name": "upscalers_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
